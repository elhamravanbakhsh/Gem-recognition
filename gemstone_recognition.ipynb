{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import cv2\n",
    "from random import randint\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_w, img_h = 224, 224    \n",
    "hist_w, hist_h = 192, 192  \n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.001\n",
    "n_epochs = 40\n",
    "print_every = 10\n",
    "train_dir = '/home/elham/Desktop/gemstone/data/train/'\n",
    "test_dir = '/home/elham/Desktop/gemstone/data/test/'\n",
    "device = torch.device(\"cuda\")\n",
    "net = models.wide_resnet50_2(pretrained=True) \n",
    "net = net.to(device)\n",
    "\n",
    "def read_imgs_lbls(_dir):\n",
    "    Images, Labels, Hists, Masks, Results = [], [], [], [], []\n",
    "    for root, dirs, files in os.walk(_dir):\n",
    "        f = os.path.basename(root)         \n",
    "        for file in files:\n",
    "            Labels.append(f)\n",
    "            try:\n",
    "                image = cv2.imread(root+'/'+file)\n",
    "                \n",
    "                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "                original = image.copy()\n",
    "                hsv_lower = np.array([0,0,20])\n",
    "                hsv_upper = np.array([255,255,255])\n",
    "                mask = cv2.inRange(hsv, hsv_lower, hsv_upper)\n",
    "                result = cv2.bitwise_and(original, original, mask=mask)\n",
    "                \n",
    "                image = cv2.resize(image,(int(img_w*1.5), int(img_h*1.5)))       \n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB);\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "                image_rgb[:,:,0] = cv2.equalizeHist(image_rgb[:,:,0])\n",
    "                image_output = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                Images.append(image)\n",
    "                Hists.append(image_output)\n",
    "                Masks.append(mask)\n",
    "                Results.append(result)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    Images = np.array(Images)\n",
    "    Hists = np.array(Hists)\n",
    "    Masks = np.array(Masks)\n",
    "    Results = np.array(Results)\n",
    "    return (Images, Labels, Hists, Masks, Results,dirs)\n",
    "\n",
    "\n",
    "def get_class_index(Labels):\n",
    "    for i, n in enumerate(Labels):\n",
    "        for j, k in enumerate(CLASSES):    \n",
    "            if n == k:\n",
    "                Labels[i] = j\n",
    "    Labels = np.array(Labels)\n",
    "    return Labels\n",
    "\n",
    "\n",
    "Train_Imgs, labels, Train_Hists, Train_Masks, Train_Results,dirs = read_imgs_lbls(train_dir)\n",
    "CLASSES= list(set(labels))\n",
    "Train_Lbls = get_class_index(labels)\n",
    "Test_Imgs, test_labels, Test_Hists, Test_Masks, Test_Results,dirs = read_imgs_lbls(test_dir)\n",
    "test_CLASSES= list(set(test_labels))\n",
    "Test_Lbls = get_class_index(test_labels)\n",
    "print(\"Dataset is loaded\")\n",
    "print('Shape of train images: {}'.format(Train_Imgs.shape))\n",
    "print('Shape of test images: {}'.format(Test_Imgs.shape))\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "\n",
    "high_thresh, low_thresh = 60, 40\n",
    "def edge_and_cut(img):\n",
    "    try:\n",
    "        img = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "        edges = cv2.Canny(img, high_thresh, low_thresh)\n",
    "        #img = remove_shadows(img)\n",
    "        \n",
    "        if(np.count_nonzero(edges)>edges.size/10000):           \n",
    "            pts = np.argwhere(edges>0)\n",
    "            y1,x1 = pts.min(axis=0)\n",
    "            y2,x2 = pts.max(axis=0)\n",
    "            \n",
    "            new_img = img[y1:y2, x1:x2]           # crop the region\n",
    "            new_img = cv2.resize(new_img,(img_w, img_h))  # Convert back\n",
    "        else:\n",
    "            new_img = cv2.resize(img,(img_w, img_h))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        new_img = cv2.resize(img,(img_w, img_h))\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "\n",
    "def crop_images(Imgs):\n",
    "    CroppedImages = np.ndarray(shape=(len(Imgs), img_w, img_h, 3), dtype=np.int)\n",
    "\n",
    "    ind = 0\n",
    "    for im in Imgs: \n",
    "        x = edge_and_cut(im)\n",
    "        CroppedImages[ind] = x\n",
    "        ind += 1\n",
    "\n",
    "    return CroppedImages\n",
    "\n",
    "NUM_CLASSES = 87\n",
    "Train_Imgs = torch.tensor(Train_Imgs).permute(0,3,1,2)\n",
    "Test_Imgs = torch.tensor(Test_Imgs).permute(0,3,1,2)\n",
    "\n",
    "train_set = torch.tensor(Train_Imgs)\n",
    "test_set = torch.tensor(Test_Imgs)\n",
    "train_label = torch.tensor(Train_Lbls)\n",
    "test_label = torch.tensor(Test_Lbls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#make a data loader\n",
    "train_input = torch.utils.data.TensorDataset(train_set, train_label)\n",
    "test_input = torch.utils.data.TensorDataset(test_set, test_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_input, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_input, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "net.fc = nn.Linear(2048, NUM_CLASSES, bias=True)\n",
    "net.fc = net.fc.to(device) if device else net.fc\n",
    "\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total= 0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data.float())\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target).item()\n",
    "        total += target.size(0)\n",
    "        if (n_epochs) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (test_loader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t.float())\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(test_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'test loss: {np.mean(val_loss):.4f}, test acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "ax.plot(train_loss, label=\"train_loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show\n",
    "\n",
    "\n",
    "#plot acc \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Test Accuracy', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "ax.plot(train_acc, label=\"train accuracy\")\n",
    "ax.plot(val_acc, label=\"test accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(net, num_images=6):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data\n",
    "        if device:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = net(inputs.float())\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        preds = preds.cpu().numpy() if device else preds.numpy()\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(2, num_images//2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            #cl = Train_Lbls[preds[j]]\n",
    "            predictes = CLASSES[preds[j]]\n",
    "            \n",
    "            #cl = Train_Lbls[labels[j]]\n",
    "            annotation = CLASSES[labels[j]]\n",
    "            \n",
    "            #ax.set_title('predictes: {}, label: {}'.format(preds[j], labels[j]))\n",
    "            ax.set_title('predictes: {}, label: {}'.format(predictes, annotation))\n",
    "            \n",
    "            img = inputs[j].permute(1,2,0).cpu().numpy().astype(np.uint8)\n",
    "            im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imshow(im_rgb)\n",
    "            if images_so_far == num_images:\n",
    "                return \n",
    "\n",
    "from pylab import *\n",
    "plt.ion()\n",
    "visualize_model(net)\n",
    "plt.ioff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
